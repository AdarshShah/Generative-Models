{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/anaconda3/envs/mtech-ai/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Upsample, AvgPool3d ,AvgPool2d, Module, Sequential, ModuleList, Conv2d, MaxPool2d, Tanh, ReLU, LeakyReLU, Flatten, Linear, Sigmoid, ConvTranspose2d, BatchNorm2d\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Initialization parameters\n",
    "device = 'cuda:0'\n",
    "datapath = '/home/adarsh/ADRL/datasets/bitmoji_faces'\n",
    "modelpath = '/home/adarsh/ADRL/assignment_1/GAN/proGAN.pt'\n",
    "modelpath2 = '/home/adarsh/ADRL/assignment_1/GAN/proGAN_l2.pt'\n",
    "modelpath3 = '/home/adarsh/ADRL/assignment_1/GAN/proGAN_l3.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 4, 4]       4,194,816\n",
      "            Conv2d-2            [-1, 512, 4, 4]       2,359,808\n",
      "            Conv2d-3            [-1, 512, 4, 4]       2,359,808\n",
      "   ConvTranspose2d-4            [-1, 512, 8, 8]       1,049,088\n",
      "            Conv2d-5            [-1, 512, 8, 8]       2,359,808\n",
      "       BatchNorm2d-6            [-1, 512, 8, 8]           1,024\n",
      "            Conv2d-7            [-1, 512, 8, 8]       2,359,808\n",
      "       BatchNorm2d-8            [-1, 512, 8, 8]           1,024\n",
      "    GeneratorBlock-9            [-1, 512, 8, 8]               0\n",
      "           Conv2d-10              [-1, 3, 8, 8]           1,539\n",
      "         Upsample-11            [-1, 512, 8, 8]               0\n",
      "           Conv2d-12            [-1, 512, 8, 8]         262,144\n",
      "           Conv2d-13              [-1, 3, 8, 8]           1,539\n",
      "================================================================\n",
      "Total params: 14,950,406\n",
      "Trainable params: 14,950,406\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.19\n",
      "Params size (MB): 57.03\n",
      "Estimated Total Size (MB): 59.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class GeneratorBlock(Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(GeneratorBlock, self).__init__()\n",
    "        self.conv1 = ConvTranspose2d(in_channels, out_channels, 2, 2)\n",
    "        self.conv2 = Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn1 = BatchNorm2d(out_channels)\n",
    "        self.conv3 = Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = self.conv1(input)\n",
    "        h = torch.nn.functional.leaky_relu(self.bn1(self.conv2(h)), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.bn2(self.conv3(h)), 0.2, True)\n",
    "        return h\n",
    "\n",
    "class Generator(Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = ConvTranspose2d(512, 512, 4, 4)\n",
    "        self.conv2 = Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv3 = Conv2d(512, 512, 3, padding=1)\n",
    "        self.blocks = ModuleList()\n",
    "        self.rgb = Conv2d(512, 3, 1)\n",
    "        self.upsample = Upsample((512, 1, 1))\n",
    "    \n",
    "    def forward(self, input, alpha=1):\n",
    "        h = self.conv1(input)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv2(h), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv3(h), 0.2, True)\n",
    "        if len(self.blocks)>0:\n",
    "            [ h:= layer(h) for layer in self.blocks[:-1] ]\n",
    "            h = alpha*torch.tanh(self.rgb(self.blocks[-1](h))) + (1-alpha)*torch.tanh(self.rgb(self.upconv(self.upsample(h))))\n",
    "        else:\n",
    "            h = torch.tanh(self.rgb(h))\n",
    "        return h\n",
    "    \n",
    "    def add_block(self, in_channels, out_channels, size):\n",
    "        self.rgb = Conv2d(out_channels, 3, 1, 1).to(device)\n",
    "        self.upsample = Upsample((size, size)).to(device)\n",
    "        self.upconv = Conv2d(in_channels, out_channels, 1, bias=False).to(device)\n",
    "        self.blocks.append(GeneratorBlock(in_channels, out_channels).to(device))\n",
    "        pass\n",
    "\n",
    "model = Generator()\n",
    "model.add_block(512, 512, 8)\n",
    "summary(model.cuda(),(512,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 512, 8, 8]           2,048\n",
      "         AvgPool3d-2            [-1, 512, 4, 4]               0\n",
      "            Conv2d-3            [-1, 512, 8, 8]       2,359,808\n",
      "            Conv2d-4            [-1, 512, 8, 8]       2,359,808\n",
      "         AvgPool2d-5            [-1, 512, 4, 4]               0\n",
      "DiscriminatorBlock-6            [-1, 512, 4, 4]               0\n",
      "            Conv2d-7            [-1, 512, 1, 1]       4,194,816\n",
      "            Conv2d-8            [-1, 512, 1, 1]         262,656\n",
      "           Flatten-9                  [-1, 512]               0\n",
      "           Linear-10                    [-1, 1]             512\n",
      "================================================================\n",
      "Total params: 9,179,648\n",
      "Trainable params: 9,179,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.95\n",
      "Params size (MB): 35.02\n",
      "Estimated Total Size (MB): 35.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class DiscriminatorBlock(Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "        self.conv1 = spectral_norm(Conv2d(in_channels, in_channels, 3, padding=1))\n",
    "        self.conv2 = spectral_norm(Conv2d(in_channels, out_channels, 3, padding=1))\n",
    "        self.pooling = AvgPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = torch.nn.functional.leaky_relu(self.conv1(h), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv2(h), 0.2, True)\n",
    "        return self.pooling(h)\n",
    "\n",
    "class Discriminator(Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.rgb = spectral_norm(Conv2d(3, 512, 1, 1))\n",
    "        self.pool = AvgPool3d(1)\n",
    "        self.conv1 = spectral_norm(Conv2d(512, 512, 4, 4))\n",
    "        self.conv2 = spectral_norm(Conv2d(512, 512, 1, 1))\n",
    "        self.blocks = ModuleList()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear = spectral_norm(Linear(512, 1, bias=False))\n",
    "\n",
    "    def forward(self, input, alpha=1):\n",
    "        h1 = torch.nn.functional.leaky_relu(self.rgb(input), 0.2, True)\n",
    "        h2 = self.pool(h1)\n",
    "        if len(self.blocks) > 0:\n",
    "            h = alpha*self.blocks[-1](h1) + (1-alpha)*h2\n",
    "            [ h:= layer(h) for layer in self.blocks[:-1] ]\n",
    "        else:\n",
    "            h = h1\n",
    "        h = torch.nn.functional.leaky_relu(self.conv1(h), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv2(h), 0.2, True)\n",
    "        h = torch.sigmoid(self.linear(self.flatten(h)))\n",
    "        return h\n",
    "    \n",
    "    def add_block(self, in_channels, out_channels):\n",
    "        self.rgb = spectral_norm(Conv2d(3, in_channels, 1, 1)).to(device)\n",
    "        kernel = in_channels/out_channels\n",
    "        self.pool = AvgPool3d((int(kernel),2,2)).to(device)\n",
    "        self.blocks.append(DiscriminatorBlock(in_channels, out_channels).to(device))\n",
    "\n",
    "model = Discriminator()\n",
    "model.add_block(512, 512)\n",
    "summary(model.cuda(),(3,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(k):\n",
    "    return torch.randn((k, 512, 1, 1)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(Discriminator(), Generator()).to(device)\n",
    "model[0].add_block(512,512)\n",
    "model[1].add_block(512,512, 8)\n",
    "model.load_state_dict(torch.load(modelpath2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = model[1](sample(1), 0.8).squeeze()\n",
    "plt.imshow(Y.detach().cpu().mean(dim=0).squeeze(),'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import torch\n",
    "from torch.nn import init, Module, ReLU, Sequential, ModuleList, Conv2d, MaxPool2d, LeakyReLU, Flatten, Linear, Sigmoid, ConvTranspose2d, BatchNorm2d, Tanh\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, z_dim=100, wasserstein=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.wass = wasserstein\n",
    "\n",
    "        # Inference over x\n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            nn.Conv2d(3, 32, 5, stride=1, bias=False),\n",
    "            nn.Conv2d(32, 64, 5, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 5, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 5, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 7, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "        ])\n",
    "\n",
    "        self.convs2 = torch.nn.ModuleList([\n",
    "            nn.Conv2d(100, 512, 1, stride=1, bias=False),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 512, 1, stride=1, bias=False)\n",
    "        ])\n",
    "\n",
    "        self.convs2 = torch.nn.ModuleList([\n",
    "            nn.Conv2d(1024, 1024, 1, stride=1, bias=False),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1024, 1, stride=1, bias=False),\n",
    "            LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, 1, stride=1, bias=False)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        [ x := conv(x) for conv in self.convs ]\n",
    "        [ z := conv(z) for conv in self.convs2 ]\n",
    "        xz = torch.cat((x,z), dim=1)\n",
    "        [ xz := conv(xz) for conv in self.convs3 ]\n",
    "\n",
    "        return torch.sigmoid(xz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1024, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = torch.zeros((128, 512, 1, 1))\n",
    "y = torch.ones((128, 512, 1, 1))\n",
    "\n",
    "z = torch.cat((x, y), dim=1)\n",
    "\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 100])\n"
     ]
    }
   ],
   "source": [
    "z = torch.ones((128, 100))\n",
    "x = z.unsqueeze(dim=2).unsqueeze(dim=3)\n",
    "y = x.squeeze(dim=-1).squeeze(dim=-1)\n",
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mtech-ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c8a66ee3e6b3d2731e4e1d203879b7efbef813706e5767cef09de0fdb5c447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
