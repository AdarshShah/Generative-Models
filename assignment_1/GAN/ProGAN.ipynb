{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/anaconda3/envs/mtech-ai/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Upsample, AvgPool3d ,AvgPool2d, Module, Sequential, ModuleList, Conv2d, MaxPool2d, Tanh, ReLU, LeakyReLU, Flatten, Linear, Sigmoid, ConvTranspose2d, BatchNorm2d\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Initialization parameters\n",
    "device = 'cuda:0'\n",
    "datapath = '/home/adarsh/ADRL/datasets/bitmoji_faces'\n",
    "modelpath = '/home/adarsh/ADRL/assignment_1/GAN/proGAN.pt'\n",
    "modelpath2 = '/home/adarsh/ADRL/assignment_1/GAN/proGAN_l2.pt'\n",
    "modelpath3 = '/home/adarsh/ADRL/assignment_1/GAN/proGAN_l3.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 4, 4]       4,194,816\n",
      "            Conv2d-2            [-1, 512, 4, 4]       2,359,808\n",
      "            Conv2d-3            [-1, 512, 4, 4]       2,359,808\n",
      "   ConvTranspose2d-4            [-1, 512, 8, 8]       1,049,088\n",
      "            Conv2d-5            [-1, 512, 8, 8]       2,359,808\n",
      "       BatchNorm2d-6            [-1, 512, 8, 8]           1,024\n",
      "            Conv2d-7            [-1, 512, 8, 8]       2,359,808\n",
      "       BatchNorm2d-8            [-1, 512, 8, 8]           1,024\n",
      "    GeneratorBlock-9            [-1, 512, 8, 8]               0\n",
      "           Conv2d-10              [-1, 3, 8, 8]           1,539\n",
      "         Upsample-11            [-1, 512, 8, 8]               0\n",
      "           Conv2d-12            [-1, 512, 8, 8]         262,144\n",
      "           Conv2d-13              [-1, 3, 8, 8]           1,539\n",
      "================================================================\n",
      "Total params: 14,950,406\n",
      "Trainable params: 14,950,406\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.19\n",
      "Params size (MB): 57.03\n",
      "Estimated Total Size (MB): 59.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class GeneratorBlock(Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(GeneratorBlock, self).__init__()\n",
    "        self.conv1 = ConvTranspose2d(in_channels, out_channels, 2, 2)\n",
    "        self.conv2 = Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn1 = BatchNorm2d(out_channels)\n",
    "        self.conv3 = Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = self.conv1(input)\n",
    "        h = torch.nn.functional.leaky_relu(self.bn1(self.conv2(h)), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.bn2(self.conv3(h)), 0.2, True)\n",
    "        return h\n",
    "\n",
    "class Generator(Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = ConvTranspose2d(512, 512, 4, 4)\n",
    "        self.conv2 = Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv3 = Conv2d(512, 512, 3, padding=1)\n",
    "        self.blocks = ModuleList()\n",
    "        self.rgb = Conv2d(512, 3, 1)\n",
    "        self.upsample = Upsample((512, 1, 1))\n",
    "    \n",
    "    def forward(self, input, alpha=1):\n",
    "        h = self.conv1(input)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv2(h), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv3(h), 0.2, True)\n",
    "        if len(self.blocks)>0:\n",
    "            [ h:= layer(h) for layer in self.blocks[:-1] ]\n",
    "            h = alpha*torch.tanh(self.rgb(self.blocks[-1](h))) + (1-alpha)*torch.tanh(self.rgb(self.upconv(self.upsample(h))))\n",
    "        else:\n",
    "            h = torch.tanh(self.rgb(h))\n",
    "        return h\n",
    "    \n",
    "    def add_block(self, in_channels, out_channels, size):\n",
    "        self.rgb = Conv2d(out_channels, 3, 1, 1).to(device)\n",
    "        self.upsample = Upsample((size, size)).to(device)\n",
    "        self.upconv = Conv2d(in_channels, out_channels, 1, bias=False).to(device)\n",
    "        self.blocks.append(GeneratorBlock(in_channels, out_channels).to(device))\n",
    "        pass\n",
    "\n",
    "model = Generator()\n",
    "model.add_block(512, 512, 8)\n",
    "summary(model.cuda(),(512,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 512, 8, 8]           2,048\n",
      "         AvgPool3d-2            [-1, 512, 4, 4]               0\n",
      "            Conv2d-3            [-1, 512, 8, 8]       2,359,808\n",
      "            Conv2d-4            [-1, 512, 8, 8]       2,359,808\n",
      "         AvgPool2d-5            [-1, 512, 4, 4]               0\n",
      "DiscriminatorBlock-6            [-1, 512, 4, 4]               0\n",
      "            Conv2d-7            [-1, 512, 1, 1]       4,194,816\n",
      "            Conv2d-8            [-1, 512, 1, 1]         262,656\n",
      "           Flatten-9                  [-1, 512]               0\n",
      "           Linear-10                    [-1, 1]             512\n",
      "================================================================\n",
      "Total params: 9,179,648\n",
      "Trainable params: 9,179,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.95\n",
      "Params size (MB): 35.02\n",
      "Estimated Total Size (MB): 35.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class DiscriminatorBlock(Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "        self.conv1 = spectral_norm(Conv2d(in_channels, in_channels, 3, padding=1))\n",
    "        self.conv2 = spectral_norm(Conv2d(in_channels, out_channels, 3, padding=1))\n",
    "        self.pooling = AvgPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = torch.nn.functional.leaky_relu(self.conv1(h), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv2(h), 0.2, True)\n",
    "        return self.pooling(h)\n",
    "\n",
    "class Discriminator(Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.rgb = spectral_norm(Conv2d(3, 512, 1, 1))\n",
    "        self.pool = AvgPool3d(1)\n",
    "        self.conv1 = spectral_norm(Conv2d(512, 512, 4, 4))\n",
    "        self.conv2 = spectral_norm(Conv2d(512, 512, 1, 1))\n",
    "        self.blocks = ModuleList()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear = spectral_norm(Linear(512, 1, bias=False))\n",
    "\n",
    "    def forward(self, input, alpha=1):\n",
    "        h1 = torch.nn.functional.leaky_relu(self.rgb(input), 0.2, True)\n",
    "        h2 = self.pool(h1)\n",
    "        if len(self.blocks) > 0:\n",
    "            h = alpha*self.blocks[-1](h1) + (1-alpha)*h2\n",
    "            [ h:= layer(h) for layer in self.blocks[:-1] ]\n",
    "        else:\n",
    "            h = h1\n",
    "        h = torch.nn.functional.leaky_relu(self.conv1(h), 0.2, True)\n",
    "        h = torch.nn.functional.leaky_relu(self.conv2(h), 0.2, True)\n",
    "        h = torch.sigmoid(self.linear(self.flatten(h)))\n",
    "        return h\n",
    "    \n",
    "    def add_block(self, in_channels, out_channels):\n",
    "        self.rgb = spectral_norm(Conv2d(3, in_channels, 1, 1)).to(device)\n",
    "        kernel = in_channels/out_channels\n",
    "        self.pool = AvgPool3d((int(kernel),2,2)).to(device)\n",
    "        self.blocks.append(DiscriminatorBlock(in_channels, out_channels).to(device))\n",
    "\n",
    "model = Discriminator()\n",
    "model.add_block(512, 512)\n",
    "summary(model.cuda(),(3,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(k):\n",
    "    return torch.randn((k, 512, 1, 1)).to(device)\n",
    "\n",
    "def discriminator_epoch(model, x, z, optim, alpha=0.2):\n",
    "    '''\n",
    "        Discriminator Loss:\n",
    "        maximize f = E[log(1-D(G(z)))] + E[log(D(x))]\n",
    "    '''\n",
    "    loss = (model[0](model[1](z, alpha), alpha) - model[0](x,alpha)).mean()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    # with torch.no_grad():\n",
    "    #     for param in model[0].parameters():\n",
    "    #         param.clamp_(-0.1, 0.1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def generator_epoch(model, X, z, optim, alpha=0.2):\n",
    "    '''\n",
    "        Generator Loss:\n",
    "        minimize f = E[log(1-D(G(z)))]\n",
    "    '''\n",
    "    loss = -model[0](model[1](z,alpha),alpha).mean()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect modelpath\n"
     ]
    }
   ],
   "source": [
    "bitmoji_transform = transforms.Compose([transforms.Resize((4,4)), transforms.ToTensor()])\n",
    "bitmoji_transform_2 = transforms.Compose([transforms.Resize((8,8)), transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=datapath, transform=bitmoji_transform)\n",
    "dataset_2 = datasets.ImageFolder(root=datapath, transform=bitmoji_transform_2)\n",
    "\n",
    "train_dataset = Subset(dataset, torch.arange(300))\n",
    "\n",
    "model = Sequential(Discriminator(), Generator()).to(device)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(modelpath))\n",
    "except:\n",
    "    print('incorrect modelpath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = model[1](sample(1)).squeeze()\n",
    "plt.imshow(Y.detach().cpu().mean(dim=0).squeeze(),'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAD8CAYAAAB6iWHJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANGklEQVR4nO3df+hd9X3H8edLjU6skkl0yWKmhYVKV/DHQqoII+vqiEFI/5AR/6hFBl8qdliYsLKBY//tr8I0RSdUplDaFWxd6NIVVzqMUNukIXFG6wxOTDAs/kqiGBbi3vvjHsOXbz/f/Lrnnvv9Js8HXL7n3PPJeX9ufrxy7znnnneqCkma64JpT0DSwmQ4SGoyHCQ1GQ6SmgwHSU2Gg6Smi8b5xUmuBP4ZuA54A/izqnq/Me4N4APgY+B4Va0Zp66kyRv3ncM3gJ9W1Wrgp936fP64qm40GKTFYdxw2Ag82S0/CXxpzP1JWiAyzhWSSQ5V1dJZ6+9X1W83xv038D5QwD9W1eMn2ecMMANw2WWX/eH1119/1vNbqI4dOzbtKegMXXzxxdOewkS88cYbvPPOO2ltO+UxhyT/DixvbPqbM5jDbVX1VpKrgWeT/LqqnmsN7ILjcYA1a9bU9u3bz6DM4vDmm29OewoTc8EF5+Yx7lWrVk17ChOxZs38n/JPGQ5V9cX5tiX5nyQrqupAkhXAwXn28Vb382CSHwJrgWY4SFoYxo35LcBXuuWvAP8yd0CSy5Jc/sky8KfAS2PWlTRh44bD3wO3J3kNuL1bJ8nvJtnajfkd4Pkku4FfAv9aVf82Zl1JEzbWdQ5V9S7wJ43n3wI2dMuvAzeMU0fS8M7No0eSxmY4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIauolHJKsT/Jqkr1JfqPrVUYe7ra/mOTmPupKmpyxwyHJhcC3gDuAzwJ3J/nsnGF3AKu7xwzw6Lh1JU1WH+8c1gJ7q+r1qjoGfI9Rm7zZNgJP1cgLwNKuz4WkBaqPcFgJ7Ju1vr977kzHSFpA+giHVp+9uQ04T2fMaGAyk2RHkh1vv/322JOTdHb6CIf9wOxGgtcAb53FGGDUK7Oq1lTVmquuuqqH6Uk6G32Ew3ZgdZJPJ7kY2MSoTd5sW4B7urMWtwCHq+pAD7UlTchYHa8Aqup4kq8BPwEuBJ6oqj1JvtptfwzYyqgD1l7gI+DecetKmqyxwwGgqrYyCoDZzz02a7mA+/uoJWkYXiEpqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoaqlfmuiSHk+zqHg/1UVfS5Ix9g9lZvTJvZ9SfYnuSLVX18pyh26rqznHrSRpGH3efPtErEyDJJ70y54bDGTt27Bj79u079cBFZv369dOewsSMbjR+7tm2bdu0pzARx48fn3fbUL0yAW5NsjvJj5P8wXw7m90O77333uthepLOxlC9MncC11bVDcAjwDPz7Wx2O7wrr7yyh+lJOhuD9MqsqiNV9WG3vBVYkmRZD7UlTcggvTKTLE+SbnltV/fdHmpLmpChemXeBdyX5DhwFNhU5+qRK+kcMVSvzM3A5j5qSRqGV0hKajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNfXVDu+JJAeTvDTP9iR5uGuX92KSm/uoK2ly+nrn8E/Aydo43QGs7h4zwKM91ZU0Ib2EQ1U9B5ysPdVG4KkaeQFYmmRFH7UlTcZQxxxOt2We7fCkBWKocDidlnmjJ22HJy0IQ4XDKVvmSVpYhgqHLcA93VmLW4DDVXVgoNqSzkIvHa+SfBdYByxLsh/4W2AJnOh8tRXYAOwFPgLu7aOupMnpqx3e3afYXsD9fdSSNAyvkJTUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqGqod3rokh5Ps6h4P9VFX0uT0cg9JRu3wNgNPnWTMtqq6s6d6kiZsqHZ4khaZvt45nI5bk+xm1Mzmwara0xqUZIZRs12uvvpqXnvttQGnOIxLLrlk2lOYmN27d097ChOxZ0/zr+uid/To0Xm3DXVAcidwbVXdADwCPDPfwNnt8JYuXTrQ9CTNNUg4VNWRqvqwW94KLEmybIjaks7OIOGQZHmSdMtru7rvDlFb0tkZqh3eXcB9SY4DR4FNXRcsSQvUUO3wNjM61SlpkfAKSUlNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6SmscMhyaokP0vySpI9SR5ojEmSh5PsTfJikpvHrStpsvq4h+Rx4C+rameSy4FfJXm2ql6eNeYOYHX3+DzwaPdT0gI19juHqjpQVTu75Q+AV4CVc4ZtBJ6qkReApUlWjFtb0uT0eswhyXXATcAv5mxaCeybtb6f3wyQT/Yxk2RHkh2HDh3qc3qSzkBv4ZDkU8DTwNer6sjczY1f0uxbYTs8aWHoJRySLGEUDN+pqh80huwHVs1av4ZRQ11JC1QfZysCfBt4paq+Oc+wLcA93VmLW4DDVXVg3NqSJqePsxW3AV8G/jPJru65vwZ+D060w9sKbAD2Ah8B9/ZQV9IEjR0OVfU87WMKs8cUcP+4tSQNxyskJTUZDpKaDAdJTYaDpCbDQVKT4SCpyXCQ1GQ4SGoyHCQ1GQ6SmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpqGaoe3LsnhJLu6x0Pj1pU0WUO1wwPYVlV39lBP0gCGaocnaZHp453DCSdphwdwa5LdjJrZPFhVe+bZxwwwA7B8+XKuuOKKPqe4IFx0Ua+/7QvKzTefmw3UL7300mlPYSIuuGD+9wdDtcPbCVxbVTcAjwDPzLcf2+FJC8Mg7fCq6khVfdgtbwWWJFnWR21JkzFIO7wky7txJFnb1X133NqSJmeodnh3AfclOQ4cBTZ1XbAkLVBDtcPbDGwet5ak4XiFpKQmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpCbDQVJTHzeY/a0kv0yyu2uH93eNMUnycJK9SV5Mcm42N5DOIX3cYPZ/gS9U1YfdLeqfT/Ljqnph1pg7gNXd4/PAo91PSQtUH+3w6pOeFMCS7jH3ztIbgae6sS8AS5OsGLe2pMnpq6nNhd1t6Q8Cz1bV3HZ4K4F9s9b3Yz9NaUHrJRyq6uOquhG4Blib5HNzhrRuXd/sW5FkJsmOJDsOHTrUx/QknYVez1ZU1SHgP4D1czbtB1bNWr+GUUPd1j7slSktAH2crbgqydJu+VLgi8Cv5wzbAtzTnbW4BThcVQfGrS1pcvo4W7ECeDLJhYzC5vtV9aMkX4UT7fC2AhuAvcBHwL091JU0QX20w3sRuKnx/GOzlgu4f9xakobjFZKSmgwHSU2Gg6Qmw0FSk+EgqclwkNRkOEhqMhwkNRkOkpoMB0lNhoOkJsNBUpPhIKnJcJDUZDhIajIcJDUZDpKaDAdJTYaDpKahemWuS3I4ya7u8dC4dSVN1lC9MgG2VdWdPdSTNIA+7j5dwKl6ZUpaZDL6tz3mTkY9K34F/D7wrar6qznb1wFPM+p89RbwYFXtmWdfM8BMt/oZ4NWxJ3h6lgHvDFRrSL6uxWfI13ZtVV3V2tBLOJzY2ajz1Q+Bv6iql2Y9fwXwf91Hjw3AP1TV6t4K9yDJjqpaM+159M3XtfgslNc2SK/MqjpSVR92y1uBJUmW9VlbUr8G6ZWZZHmSdMtru7rvjltb0uQM1SvzLuC+JMeBo8Cm6vPzTD8en/YEJsTXtfgsiNfW6zEHSecOr5CU1GQ4SGo678MhyfokrybZm+Qb055PX5I8keRgkpdOPXrxSLIqyc+SvNJdrv/AtOfUh9P5GsLgczqfjzl0B1H/C7id0QVa24G7q+rlqU6sB0n+iNGVq09V1eemPZ++JFkBrKiqnUkuZ3Tx3ZcW+59ZdzbvstlfQwAeaHwNYTDn+zuHtcDeqnq9qo4B3wM2TnlOvaiq54D3pj2PvlXVgara2S1/ALwCrJzurMZXIwvqawjnezisBPbNWt/POfAX7XyR5DrgJuAXU55KL5JcmGQXcBB4tqqm+rrO93BI47nz93PWIpLkU4y+r/P1qjoy7fn0oao+rqobgWuAtUmm+nHwfA+H/cCqWevXMPpimBaw7jP508B3quoH055P3+b7GsLQzvdw2A6sTvLpJBcDm4AtU56TTqI7cPdt4JWq+ua059OX0/kawtDO63CoquPA14CfMDqw9f35vkq+2CT5LvBz4DNJ9if582nPqSe3AV8GvjDrzmIbpj2pHqwAfpbkRUb/aT1bVT+a5oTO61OZkuZ3Xr9zkDQ/w0FSk+EgqclwkNRkOEhqMhwkNRkOkpr+H4D1KWVjS9n3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[5346][0].mean(dim=0).squeeze(),'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 : : 100%|█████████▉| 508/509 [02:21<00:00,  3.58it/s, loss=(-0.013406169600784779, -0.5231168270111084)]  \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "optim_generator = torch.optim.Adam(model[1].parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "optim_discriminator = torch.optim.Adam(model[0].parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "finished = 0\n",
    "for ep in range(1):\n",
    "    try:\n",
    "        with tqdm(train_dataloader) as tepoch:\n",
    "            tepoch.set_description(f'Epoch {ep+1} : ')\n",
    "            for X, _ in tepoch:\n",
    "                loss = discriminator_epoch(model, X.to(device), sample(batch_size), optim_discriminator).item(\n",
    "                ), generator_epoch(model, X.to(device), sample(batch_size), optim_generator).item()\n",
    "                tepoch.set_postfix({'loss': loss})\n",
    "                tepoch.refresh()\n",
    "                i += 1\n",
    "                if i % 10 == 0:\n",
    "                    torch.save(model.state_dict(), modelpath)\n",
    "            if finished:\n",
    "                break\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 : : 100%|█████████▉| 508/509 [09:38<00:01,  1.14s/it, loss=(3.025063779205084e-05, -0.4549545645713806)]  \n",
      "Epoch 2 : : 100%|█████████▉| 508/509 [09:36<00:01,  1.14s/it, loss=(5.620997399091721e-06, -0.48597556352615356)]  \n",
      "Epoch 3 : : 100%|█████████▉| 508/509 [09:38<00:01,  1.14s/it, loss=(3.88571061193943e-06, -0.49640506505966187)]   \n",
      "Epoch 4 : : 100%|█████████▉| 508/509 [09:37<00:01,  1.14s/it, loss=(7.05057755112648e-06, -0.4995293617248535)]    \n",
      "Epoch 5 : : 100%|█████████▉| 508/509 [09:37<00:01,  1.14s/it, loss=(-1.050299033522606e-06, -0.5001227855682373)] \n",
      "Epoch 6 : : 100%|█████████▉| 508/509 [09:37<00:01,  1.14s/it, loss=(-1.318054273724556e-06, -0.5012238621711731)] \n",
      "Epoch 7 : : 100%|█████████▉| 508/509 [09:37<00:01,  1.14s/it, loss=(1.7872080206871033e-06, -0.501354992389679)]  \n",
      "Epoch 8 : : 100%|█████████▉| 508/509 [09:38<00:01,  1.14s/it, loss=(-1.6065314412117004e-08, -0.503312349319458)]  \n",
      "Epoch 9 : :  42%|████▏     | 212/509 [04:02<05:39,  1.14s/it, loss=(7.119961082935333e-07, -0.502670168876648)]   \n",
      "Epoch 10 : :   2%|▏         | 10/509 [00:11<09:25,  1.13s/it, loss=(2.0600855350494385e-06, -0.5026862621307373)]"
     ]
    }
   ],
   "source": [
    "model = Sequential(Discriminator(), Generator()).to(device)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(modelpath))\n",
    "except:\n",
    "    print('incorrect modelpath')\n",
    "\n",
    "model[0].add_block(512,512)\n",
    "model[1].add_block(512,512, 8)    \n",
    "\n",
    "i = 0\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(dataset_2, batch_size=batch_size)\n",
    "optim_generator = torch.optim.Adam(model[1].parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "optim_discriminator = torch.optim.Adam(model[0].parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "alpha = 0\n",
    "finished = 0\n",
    "for ep in range(11):\n",
    "    try:\n",
    "        with tqdm(train_dataloader) as tepoch:\n",
    "            tepoch.set_description(f'Epoch {ep+1} : ')\n",
    "            for X, _ in tepoch:\n",
    "                if alpha>1:\n",
    "                    finished=1\n",
    "                    break\n",
    "                loss = discriminator_epoch(model, X.to(device), sample(batch_size), optim_discriminator, alpha).item(\n",
    "                ), generator_epoch(model, X.to(device), sample(batch_size), optim_generator, alpha).item()\n",
    "                g_loss = loss[1]\n",
    "                count = 0\n",
    "                while count <= 4 and g_loss>=-0.6:\n",
    "                    g_loss = generator_epoch(model, X.to(device), sample(batch_size), optim_generator, alpha).item()\n",
    "                    count += 1\n",
    "                tepoch.set_postfix({'loss': loss})\n",
    "                tepoch.refresh()\n",
    "                i += 1\n",
    "                if i % 10 == 0:\n",
    "                    torch.save(model.state_dict(), modelpath2)\n",
    "            if finished:\n",
    "                break\n",
    "        alpha += 0.2\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Discriminator(), Generator()).to(device)\n",
    "model[0].add_block(512,512)\n",
    "model[1].add_block(512,512, 8)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(modelpath2))\n",
    "except:\n",
    "    print('incorrect modelpath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model[1](sample(1),0).squeeze()\n",
    "plt.imshow(Y.detach().cpu().mean(dim=0).squeeze(),'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset_2[5346][0].mean(dim=0).squeeze(),'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Discriminator(), Generator()).to(device)\n",
    "model[0].add_block(512,512)\n",
    "model[1].add_block(512,512, 8)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(modelpath2))\n",
    "except:\n",
    "    print('incorrect modelpath')\n",
    "i = 0\n",
    "model[0].add_block(512,512)\n",
    "model[1].add_block(512,512, 16)\n",
    "batch_size = 128\n",
    "bitmoji_transform_3 = transforms.Compose([transforms.Resize((16,16)), transforms.ToTensor()])\n",
    "dataset_3 = datasets.ImageFolder(root=datapath, transform=bitmoji_transform_3)\n",
    "train_dataloader = DataLoader(dataset_3, batch_size=batch_size)\n",
    "optim_generator = torch.optim.Adam(model[1].parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "optim_discriminator = torch.optim.Adam(model[0].parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "alpha = 0\n",
    "for ep in range(50):\n",
    "    with tqdm(train_dataloader) as tepoch:\n",
    "        tepoch.set_description(f'Epoch {ep+1} : ')\n",
    "        for X, _ in tepoch:\n",
    "            if alpha > 1:\n",
    "                break\n",
    "            loss = discriminator_epoch(model, X.to(device), sample(batch_size), optim_discriminator, alpha).item(\n",
    "            ), generator_epoch(model, X.to(device), sample(batch_size), optim_generator, alpha).item()\n",
    "            g_loss = loss[1]\n",
    "            count = 0\n",
    "            while count <= 4 and g_loss>=-0.6:\n",
    "                g_loss = generator_epoch(model, X.to(device), sample(batch_size), optim_generator, alpha).item()\n",
    "                count += 1\n",
    "            tepoch.set_postfix({'loss': loss})\n",
    "            tepoch.refresh()\n",
    "            i += 1\n",
    "            if i % 10 == 0:\n",
    "                torch.save(model.state_dict(), modelpath2)\n",
    "        alpha += 0.2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mtech-ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c8a66ee3e6b3d2731e4e1d203879b7efbef813706e5767cef09de0fdb5c447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
